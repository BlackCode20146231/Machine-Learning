{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAk/uRODJnTjZuw/1EPzuC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlackCode20146231/Machine-Learning/blob/main/CHAPTER_13_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13.1 Fitting a Line"
      ],
      "metadata": {
        "id": "DVBA2Kl0zLKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You want to train a model that represents a linear relationship between the feature\n",
        "and target vector.\n",
        "\n",
        "Use a linear regression (in scikit-learn, LinearRegression):"
      ],
      "metadata": {
        "id": "yb2roL5PzPUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn==1.1.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCfCB6wmzT64",
        "outputId": "fd2cabac-62c1-49df-9a5a-f385dc4c1811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn==1.1.3 in /usr/local/lib/python3.9/dist-packages (1.1.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.3) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.3) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.3) (1.22.4)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.3) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_boston\n",
        "# Load data with only two features\n",
        "boston = load_boston()\n",
        "features = boston.data[:,0:2]\n",
        "target = boston.target\n",
        "# Create linear regression\n",
        "regression = LinearRegression()\n",
        "# Fit the linear regression\n",
        "model = regression.fit(features, target)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZAy0wbb0qcn",
        "outputId": "08c7b64b-8889-4ec2-e714-f333899634fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discussion"
      ],
      "metadata": {
        "id": "B2gXyWhV5cB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the intercept\n",
        "model.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSfKsuoP5XEo",
        "outputId": "b75f3159-72b5-4274-852f-26735de72e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.1018903275908265"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the feature coefficients\n",
        "model.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk3guyEW5jX1",
        "outputId": "5ece2a32-ba82-404e-f390-2d86dd0c7fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.35207832,  0.11610909])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First value in the target vector multiplied by 1000\n",
        "target[0]*1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eax8rfdq5lWC",
        "outputId": "1290de63-2a19-4352-e418-bbc9b754af60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24000.0"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(features)[0]*1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMOt3oyU58xQ",
        "outputId": "e5a5a7ba-1c06-44b2-e94d-7b02df611f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24573.366631705547"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First coefficient multiplied by 1000\n",
        "model.coef_[0]*1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0bBrdWq5_0A",
        "outputId": "36285864-9e92-4ada-e337-d2987426fde7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-352.07831564026765"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13.2 Handling Interactive Effects"
      ],
      "metadata": {
        "id": "ZWSn-Kal59-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have a feature whose effect on the target variable depends on another feature\n",
        "\n",
        "Create an interaction term to capture that dependence using scikit-learn’s Polynomial \n",
        "\n",
        "Features:"
      ],
      "metadata": {
        "id": "BQ_KZswO6aNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "# Load data with only two features\n",
        "boston = load_boston()\n",
        "features = boston.data[:,0:2]\n",
        "target = boston.target\n",
        "# Create interaction term\n",
        "interaction = PolynomialFeatures(\n",
        " degree=3, include_bias=False, interaction_only=True)\n",
        "features_interaction = interaction.fit_transform(features)\n",
        "# Create linear regression\n",
        "regression = LinearRegression()\n",
        "# Fit the linear regression\n",
        "model = regression.fit(features_interaction, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mABrH1Ph6DHI",
        "outputId": "62c2546a-8512-45c5-881f-f1f182789d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**"
      ],
      "metadata": {
        "id": "6Oh1D_pQ6HqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the feature values for first observation\n",
        "features[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqsr6TaO6Iwm",
        "outputId": "a70d5249-24d1-4e5f-8f2e-8d5c92dcf5cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.32e-03, 1.80e+01])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library\n",
        "import numpy as np\n",
        "# For each observation, multiply the values of the first and second feature\n",
        "interaction_term = np.multiply(features[:, 0], features[:, 1])"
      ],
      "metadata": {
        "id": "oXJrNXnV6NU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View interaction term for first observation\n",
        "interaction_term[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiLSbETg6N4-",
        "outputId": "67673b0c-8f8e-4dcc-de99-b71bd52537bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11376"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the values of the first observation\n",
        "features_interaction[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2jP6aGb6TE-",
        "outputId": "510daf66-bddb-405b-9a91-4027d5b3cd49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.3200e-03, 1.8000e+01, 1.1376e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13.3 Fitting a Nonlinear Relationship"
      ],
      "metadata": {
        "id": "Wn0X_CBH6WLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You want to model a nonlinear relationship\n",
        "\n",
        "Create a polynomial regression by including polynomial features in a linear regres‐\n",
        "sion model:"
      ],
      "metadata": {
        "id": "C9WToj286pJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "# Load data with one feature\n",
        "boston = load_boston()\n",
        "features = boston.data[:,0:1]\n",
        "target = boston.target\n",
        "# Create polynomial features x^2 and x^3\n",
        "polynomial = PolynomialFeatures(degree=3, include_bias=False)\n",
        "features_polynomial = polynomial.fit_transform(features)\n",
        "# Create linear regression\n",
        "regression = LinearRegression()\n",
        "# Fit the linear regression\n",
        "model = regression.fit(features_polynomial, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSFJHYFz6V3X",
        "outputId": "cb169b92-7a6d-4a46-bf78-d6a8d13a025d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**"
      ],
      "metadata": {
        "id": "9JOtkZgt641w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View first observation\n",
        "features[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz6ZtfI07BRj",
        "outputId": "c8cd71f6-cecd-4067-c88a-953e5fa478e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00632])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View first observation raised to the second power, x^2\n",
        "features[0]**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww_iQtv_7F4t",
        "outputId": "cea9dd28-22c5-41a0-d79b-ff4962acbde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.99424e-05])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features[0]**3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lG4AVY17Iv9",
        "outputId": "ba3eac11-4888-401d-da36-f2a08626f747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.52435968e-07])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first observation's values for x, x^2, and x^3\n",
        "features_polynomial[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DMKceDq7OLW",
        "outputId": "ec69f644-e214-4fbc-d2c1-c2c712a80cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.32000000e-03, 3.99424000e-05, 2.52435968e-07])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13.4 Reducing Variance with Regularization"
      ],
      "metadata": {
        "id": "2zqJp6Ux7VCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You want to reduce the variance of your linear regression model\n",
        "\n",
        "Use a learning algorithm that includes a shrinkage penalty (also called regularization)\n",
        "like ridge regression and lasso regression:"
      ],
      "metadata": {
        "id": "sxV5Vhxt7YNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load data\n",
        "boston = load_boston()\n",
        "features = boston.data\n",
        "target = boston.target\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "# Create ridge regression with an alpha value\n",
        "regression = Ridge(alpha=0.5)\n",
        "# Fit the linear regression\n",
        "model = regression.fit(features_standardized, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbdrjggf7Wz-",
        "outputId": "604d9bbf-fabc-4c77-d7be-0881ea80c107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**"
      ],
      "metadata": {
        "id": "scO42kgu7il3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from sklearn.linear_model import RidgeCV\n",
        "# Create ridge regression with three alpha values\n",
        "regr_cv = RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
        "# Fit the linear regression\n",
        "model_cv = regr_cv.fit(features_standardized, target)\n",
        "# View coefficients\n",
        "model_cv.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FHeEcZs7iBv",
        "outputId": "2c0774e4-d999-4bce-dc73-8453a41d406d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.91987132,  1.06646104,  0.11738487,  0.68512693, -2.02901013,\n",
              "        2.68275376,  0.01315848, -3.07733968,  2.59153764, -2.0105579 ,\n",
              "       -2.05238455,  0.84884839, -3.73066646])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View alpha\n",
        "model_cv.alpha_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0SFJG_u7oed",
        "outputId": "22d3e285-70f8-4d77-813f-a71d014cb08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13.5 Reducing Features with Lasso Regression"
      ],
      "metadata": {
        "id": "m8YHr4wS7qnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You want to simplify your linear regression model by reducing the number of fea‐\n",
        "tures.\n",
        "\n",
        "Use a lasso regression"
      ],
      "metadata": {
        "id": "sJfNM9m67vPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load data\n",
        "boston = load_boston()\n",
        "features = boston.data\n",
        "target = boston.target\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "# Create lasso regression with alpha value\n",
        "regression = Lasso(alpha=0.5)\n",
        "# Fit the linear regression\n",
        "model = regression.fit(features_standardized, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBPZAPZT7pAV",
        "outputId": "fb38fc73-92ef-4962-e2a8-9eaefd5789fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**"
      ],
      "metadata": {
        "id": "RMMwPoLP8NDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View coefficients\n",
        "model.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM2KjF9979Nb",
        "outputId": "27e30eac-6461-42a5-d112-c7272cd1b430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.11526463,  0.        , -0.        ,  0.39707879, -0.        ,\n",
              "        2.97425861, -0.        , -0.17056942, -0.        , -0.        ,\n",
              "       -1.59844856,  0.54313871, -3.66614361])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lasso regression with a high alpha\n",
        "regression_a10 = Lasso(alpha=10)\n",
        "model_a10 = regression_a10.fit(features_standardized, target)\n",
        "model_a10.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GmOAdtb8PF6",
        "outputId": "495f9952-bd9e-411e-b2e5-78a28c062c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.,  0., -0.,  0., -0.,  0., -0.,  0., -0., -0., -0.,  0., -0.])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}